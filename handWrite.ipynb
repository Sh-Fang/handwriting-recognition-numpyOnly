{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZUwG7ospUqzN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "###############第一节课：搭建网络框架、初始化网络参数##########################\n",
        "dimensions=[28*28, 10]    #第一个参数是图片的维度，第二个参数是output的维度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IPBxsuG-iqCb"
      },
      "outputs": [],
      "source": [
        "#定义激活函数\n",
        "def tanh(x):\n",
        "    x=np.array(x)\n",
        "    return np.tanh(x)\n",
        "\n",
        "    \n",
        "def softmax(x):\n",
        "    x=np.array(x)\n",
        "    exp = np.exp(x-x.max())   # x-x.max()的作用是防止指数爆炸，在经过相减运算后，不影响最后的结果\n",
        "    return exp/exp.sum()      #因为在代码中使用了x.max()，而普通数组是没有这样的max函数的，而np.array()有\n",
        "                              #所以在传参进softmax(x)时，要传进来np.array(x)\n",
        "\n",
        "                             "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#定义初始化参数的函数\n",
        "def init_parematers(input_dim, output_dim):  #参数为输入图片的维度和输出图片的维度\n",
        "    b0 = np.zeros(input_dim)   #b0为全零，大小为784*1\n",
        "    b1 = np.zeros(output_dim)  #b1为全零，大小为10*1\n",
        "    w1 = np.random.rand(input_dim, output_dim)**np.sqrt(2/784)  #w1为随机，大小为784*10\n",
        "    \n",
        "    init_parameters_b_w = [   #以字典的形式返回所有参数\n",
        "        {'b0':b0},\n",
        "        {'b1':b1, 'w1':w1}\n",
        "    ]\n",
        "    return init_parameters_b_w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "##########################第二节课：读取并显示MNIST中的数据##################################\n",
        "#设置训练集，验证集和测试集\n",
        "train_set_num = 50000\n",
        "valid_set_num = 10000\n",
        "test_set_num = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "#读取MNIST文件\n",
        "import os\n",
        "\n",
        "root_path = os.path.abspath('.')  #获取当前文件夹的绝对路径\n",
        "\n",
        "train_img_path = os.path.join(root_path,\"MNIST\\\\train-images.idx3-ubyte\") #join()函数能将两个参数地址拼接到一起\n",
        "train_lab_path = os.path.join(root_path,\"MNIST\\\\train-labels.idx1-ubyte\")\n",
        "\n",
        "test_img_path = os.path.join(root_path,\"MNIST\\\\t10k-images.idx3-ubyte\")\n",
        "test_lab_path = os.path.join(root_path,\"MNIST\\\\t10k-labels.idx1-ubyte\")\n",
        "\n",
        "# 读取训练集中的图片数据\n",
        "with open(train_img_path, 'rb') as t:  \n",
        "    t.seek(16)    #因为train-images.idx3-ubyte中，前16个字节的数据是描述这个文件的，所以真正的数据是从16后面开始的\n",
        "    train_img = np.fromfile(t,dtype=np.uint8).reshape(-1,28*28)  #np.fromfile()作用：从文本或二进制文件中的数据构造一个数组\n",
        "    #reshape(-1,28*28)的解释：-1代表自动检测，因为不知道源文件中有多少个手写体数字，但是知道每个图片都是28*28的，所以第一个参数为-1就代表自动检测文件中有多少个28*28的图片\n",
        "    train_img = train_img[:train_set_num]   #从60000训练集中分离出前50000个为真正的训练集\n",
        "    valid_img = train_img[valid_set_num:]   #从60000训练集中分离出后10000个为验证集\n",
        "\n",
        "# 读取训练集中的标签数据\n",
        "with open(train_lab_path, 'rb') as t:  \n",
        "    t.seek(8)    #在train-labels.idx1-ubyte中，前8个字节的数据是描述这个文件的\n",
        "    train_lab = np.fromfile(t,dtype=np.uint8)\n",
        "    train_lab = train_lab[:train_set_num]   \n",
        "    valid_lab = train_lab[valid_set_num:]\n",
        "\n",
        "# 读取测试集中的图片数据\n",
        "with open(test_img_path, 'rb') as t:  \n",
        "    t.seek(16) \n",
        "    test_img = np.fromfile(t,dtype=np.uint8).reshape(-1,28*28)\n",
        "\n",
        "\n",
        "# 读取测试集中的标签数据\n",
        "with open(test_lab_path, 'rb') as t:  \n",
        "    t.seek(8)    \n",
        "    test_lab = np.fromfile(t,dtype=np.uint8)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "#把数据画出来\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#画出训练集数据\n",
        "def show_train_img(index):\n",
        "    img = train_img[index].reshape(28,28)  #前面读取图片时的28*28是告诉程序每一张图片有多大，最后仍然是按行来储存读出来的数据（即:1*784的一维数据），而此处的28*28则是将读出来的那个一维数据转换成二维交给画图程序画图\n",
        "    plt.imshow(img, cmap=\"gray\")     #用灰度的格式将图片画出来\n",
        "    print(\"train_data:{}\".format(train_lab[index]))     #打印图片对应的标签\n",
        "\n",
        "#画出验证集数据\n",
        "def show_valid_img(index):\n",
        "    img = valid_img[index].reshape(28,28)\n",
        "    plt.imshow(img,cmap=\"gray\")\n",
        "    print(\"valid_data:{}\".format(valid_lab[index]))\n",
        "\n",
        "#画出测试集数据\n",
        "def show_test_img(index):\n",
        "    img = test_img[index].reshape(28,28)\n",
        "    plt.imshow(img,cmap=\"gray\")\n",
        "    print(\"test_data:{}\".format(test_lab[index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data:1\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAADKxJREFUeJzt3X+o3XUdx/HXS2ugK9ERrsuyVim6ULG8DGERRjgsBtv+SJyQC9MrOKEwJH+ADloo0c+/ghuOLaitgZojpRUSaRjDq0Tuh64tZq2NexsKc/iH6N79cb+L27zne8495/vj3L2fDxj3nO/73O/3zWGv+/me8/3xcUQIQD7ntN0AgHYQfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSX2gyY3Z5nRCoGYR4V5eN9DIb/tG26/ZPmj7vkHWBaBZ7vfcftvnSjog6QZJRyS9KGldROwr+R1GfqBmTYz8yyUdjIh/RMQ7krZLWj3A+gA0aJDwL5H0rxnPjxTL/o/tMdsTticG2BaAig3yhd9suxbv262PiHFJ4xK7/cAwGWTkPyLpkhnPPybp6GDtAGjKIOF/UdJltj9pe4GkmyXtrKYtAHXre7c/It61fbekXZLOlbQ5IvZW1hmAWvV9qK+vjfGZH6hdIyf5AJi/CD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IqtEpuoG5uOKKK0rre/f2f6f4ZcuWldYPHDjQ97rnC0Z+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0hqoOP8tg9LekvSe5LejYjRKpoCJGndunWl9VOnTvW97ltuuaW0vnHjxr7XPV9UcZLPFyPieAXrAdAgdvuBpAYNf0j6ve2XbI9V0RCAZgy6278iIo7avljSH2y/GhHPzXxB8UeBPwzAkBlo5I+Io8XPKUlPSlo+y2vGI2KULwOB4dJ3+G0vtP3h048lrZS0p6rGANRrkN3+xZKetH16Pb+KiN9V0hWA2jkimtuY3dzGMBTWrl3bsXbrrbeW/u7KlStL6wsWLOirJ0k6frz86PTIyEjf625bRLiX13GoD0iK8ANJEX4gKcIPJEX4gaQIP5AUt+7GQM4///zS+nXXXdextmrVqqrbwRww8gNJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUhznx0AefPDB0vo999zTUCdz8/TTT7fdQusY+YGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKW7djVL3339/aX3Tpk2l9UGm0a7TsmXLSusHDx5sqJPqcetuAKUIP5AU4QeSIvxAUoQfSIrwA0kRfiCprtfz294saZWkqYi4sli2SNKvJS2VdFjSTRHxZn1toi733ntvab3bcf5hdvLkyY61Js9vGVa9jPxbJN14xrL7JD0bEZdJerZ4DmAe6Rr+iHhO0htnLF4taWvxeKukNRX3BaBm/X7mXxwRxySp+HlxdS0BaELt9/CzPSZprO7tAJibfkf+SdsjklT8nOr0wogYj4jRiBjtc1sAatBv+HdKWl88Xi/pqWraAdCUruG3vU3SXyRdbvuI7W9IelTSDbb/LumG4jmAeaTrZ/6IWNeh9KWKe0ENRkZGSuvLly8vrZ933nlVtlOp119/vbR+xx13dKwdOnSo6nbmHc7wA5Ii/EBShB9IivADSRF+ICnCDyTFrbvPAgsXLuxY27JlS+nvrlkz2DVZ55xTPn4McuvuqamOJ45Kkm677bbS+q5du/re9nzGrbsBlCL8QFKEH0iK8ANJEX4gKcIPJEX4gaQ4zn8W2LFjR8fa2rVra912ncf5X3311dL6VVdd1fe6z2Yc5wdQivADSRF+ICnCDyRF+IGkCD+QFOEHkqp9ui4M7tJLLy2tl91+u9tx+EENsv59+/aV1lesWNH3utEdIz+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJNX1OL/tzZJWSZqKiCuLZRsl3SHpP8XLHoiIZ+pq8mx39dVXl9bHx8dL60uWLOlYG+R6+iq88MILHWtlU2hL0okTJ6puBzP0MvJvkXTjLMt/HBHXFP8IPjDPdA1/RDwn6Y0GegHQoEE+899t+2+2N9u+qLKOADSi3/D/TNKnJV0j6ZikH3Z6oe0x2xO2J/rcFoAa9BX+iJiMiPci4pSkn0vqeGVJRIxHxGhEjPbbJIDq9RV+2yMznq6VtKeadgA0pZdDfdskXS/pI7aPSHpY0vW2r5EUkg5LurPGHgHUoGv4I2LdLIsfq6GXtK699tqB6sPs+eef71jrdl9+1Isz/ICkCD+QFOEHkiL8QFKEH0iK8ANJcetuDGT37t2l9U2bNjXUCeaKkR9IivADSRF+ICnCDyRF+IGkCD+QFOEHkuI4fwMuvPDC0vp8nop6586dpfW33367oU4wV4z8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5CUI6K5jdnNbWyIXH755aX1PXuGd86TRx55pLT+0EMPNdQJehUR7uV1jPxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kFTX6/ltXyLpF5I+KumUpPGI+KntRZJ+LWmppMOSboqIN+trdXhdcMEFpfVt27Y11En1nnnmmbZbQE16GfnflfTtiFgm6TpJG2x/RtJ9kp6NiMskPVs8BzBPdA1/RByLiJeLx29J2i9piaTVkrYWL9sqaU1dTQKo3pw+89teKumzknZLWhwRx6TpPxCSLq66OQD16fkefrY/JOlxSd+KiBN2T6cPy/aYpLH+2gNQl55Gftsf1HTwfxkRTxSLJ22PFPURSVOz/W5EjEfEaESMVtEwgGp0Db+nh/jHJO2PiB/NKO2UtL54vF7SU9W3B6Auvez2r5D0NUmv2P5rsewBSY9K2mH7G5L+Kemr9bQ4/DZs2FBa73ZJb5v27t1bWn/zzZRHb1PoGv6I+LOkTh/wv1RtOwCawhl+QFKEH0iK8ANJEX4gKcIPJEX4gaS4dXcDJicnS+uLFi2qbdvdjuPffvvtpfWJiYkq20EDuHU3gFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BUz7fxQv/uuuuu0vr27dtr2/ahQ4dK6xzHz4uRH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeS4np+4CzD9fwAShF+ICnCDyRF+IGkCD+QFOEHkiL8QFJdw2/7Ett/tL3f9l7b3yyWb7T9b9t/Lf59pf52AVSl60k+tkckjUTEy7Y/LOklSWsk3STpZET8oOeNcZIPULteT/LpeiefiDgm6Vjx+C3b+yUtGaw9AG2b02d+20slfVbS7mLR3bb/Znuz7Ys6/M6Y7Qnb3C8KGCI9n9tv+0OS/iTpexHxhO3Fko5LCknf1fRHg9u6rIPdfqBmve729xR+2x+U9FtJuyLiR7PUl0r6bURc2WU9hB+oWWUX9ti2pMck7Z8Z/OKLwNPWStoz1yYBtKeXb/s/L+l5Sa9IOlUsfkDSOknXaHq3/7CkO4svB8vWxcgP1KzS3f6qEH6gflzPD6AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBShB9IivADSRF+IKmuN/Cs2HFJr894/pFi2TAa1t6GtS+J3vpVZW+f6PWFjV7P/76N2xMRMdpaAyWGtbdh7Uuit3611Ru7/UBShB9Iqu3wj7e8/TLD2tuw9iXRW79a6a3Vz/wA2tP2yA+gJa2E3/aNtl+zfdD2fW300Intw7ZfKWYebnWKsWIatCnbe2YsW2T7D7b/XvycdZq0lnobipmbS2aWbvW9G7YZrxvf7bd9rqQDkm6QdETSi5LWRcS+RhvpwPZhSaMR0foxYdtfkHRS0i9Oz4Zk+/uS3oiIR4s/nBdFxHeGpLeNmuPMzTX11mlm6a+rxfeuyhmvq9DGyL9c0sGI+EdEvCNpu6TVLfQx9CLiOUlvnLF4taStxeOtmv7P07gOvQ2FiDgWES8Xj9+SdHpm6Vbfu5K+WtFG+JdI+teM50c0XFN+h6Tf237J9ljbzcxi8emZkYqfF7fcz5m6ztzcpDNmlh6a966fGa+r1kb4Z5tNZJgOOayIiM9J+rKkDcXuLXrzM0mf1vQ0bsck/bDNZoqZpR+X9K2IONFmLzPN0lcr71sb4T8i6ZIZzz8m6WgLfcwqIo4WP6ckPanpjynDZPL0JKnFz6mW+/mfiJiMiPci4pSkn6vF966YWfpxSb+MiCeKxa2/d7P11db71kb4X5R0me1P2l4g6WZJO1vo431sLyy+iJHthZJWavhmH94paX3xeL2kp1rs5f8My8zNnWaWVsvv3bDNeN3KST7FoYyfSDpX0uaI+F7jTczC9qc0PdpL01c8/qrN3mxvk3S9pq/6mpT0sKTfSNoh6eOS/inpqxHR+BdvHXq7XnOcubmm3jrNLL1bLb53Vc54XUk/nOEH5MQZfkBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkvov26bGU6AN3/4AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#显示训练集图片和标签\n",
        "show_train_img(np.random.randint(50000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "valid_data:2\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#显示验证集的图片和标签\n",
        "show_valid_img(np.random.randint(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test_data:6\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#显示测试集图片和标签\n",
        "show_test_img(np.random.randint(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "################第四节课：反向传播和梯度下降更新网络中的参数#################################\n",
        "# 计算梯度下降所用到的导数\n",
        "# 注意！！！(传参时，参数中所有的x必须是np的数组对象)\n",
        "def d_tanh(x):   \n",
        "    return np.diag(1/(np.cosh(x))**2)\n",
        "\n",
        "def d_softmax(x):\n",
        "    sm=softmax(x)\n",
        "    return np.diag(sm)-np.outer(sm,sm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#计算y_real和y_predict的差值\n",
        "def diff_yreal_ypredict(img_lab,img_data,b0,b1,w1):\n",
        "    # b0=init_parematers(784, 10)[0]['b0']\n",
        "    # w1=init_parematers(784, 10)[1]['w1']\n",
        "    # b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "\n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "    l1_out=softmax(l1_in)\n",
        "\n",
        "    y_predict=l1_out #用y_predict来代表预测值\n",
        "\n",
        "    y_real=[0 for i in range(10)]  #y_real为长度为10的数组\n",
        "    y_real=np.eye(10)              #生成10*10的对角矩阵\n",
        "    y_real=y_real.reshape(-1,1*10)  #用y_real来代表真实世界的值，y_real[0]就代表[1 0 0 0 0 0 0 0 0]，即label=1的数字的理想输出, y_real[1]同理\n",
        "    \n",
        "    return y_real[img_lab]-y_predict  #返回差值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "#计算梯度下降\n",
        "\n",
        "#求L对b1的偏导数=-2 * (y-output) * d_A2\n",
        "# 注意！！！(img_lab是从0开始的，所以img_lab=1代表标签2)\n",
        "def L_to_b1(img_lab,img_data,b0,b1,w1):\n",
        "    # b0=init_parematers(784, 10)[0]['b0']\n",
        "    # w1=init_parematers(784, 10)[1]['w1']\n",
        "    # b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(img_lab,img_data,b0,b1,w1)  #求y-output的差值\n",
        "\n",
        "    result=np.dot(d_A2,diff)    #计算L对b1的偏导数的结果\n",
        "    \n",
        "    return result\n",
        "\n",
        "#求L对w1的偏导数=-2 * (y-output) * d_A2 * l0\n",
        "# 注意！！！(img_lab是从0开始的，所以img_lab=1代表标签2)\n",
        "def L_to_w1(img_lab,img_data,b0,b1,w1):\n",
        "    # b0=init_parematers(784, 10)[0]['b0']\n",
        "    # w1=init_parematers(784, 10)[1]['w1']\n",
        "    # b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(img_lab,img_data,b0,b1,w1)  #求y-output的差值\n",
        "\n",
        "    mid_temp=np.dot(d_A2,diff)    #计算L对b1的偏导数的结果\n",
        "\n",
        "    l0_out=l0_out.reshape(784,1)\n",
        "    mid_temp=mid_temp.reshape(1,10)\n",
        "\n",
        "    result=np.dot(l0_out,mid_temp)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "#求L对b1的偏导数=-2 * (y-output) * d_A2 * w1 * d_A1  (d_A2代表队A2求导，A2是第二层的激活函数“softmax”，A1是第一层的激活函数“tanh”)\n",
        "# 注意！！！(img_lab是从0开始的，所以img_lab=1代表标签2)\n",
        "def L_to_b0(img_lab,img_data,b0,b1,w1):\n",
        "    # b0=init_parematers(784, 10)[0]['b0']\n",
        "    # w1=init_parematers(784, 10)[1]['w1']\n",
        "    # b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1  #l1=softmax(w1*l0+b1)   (注意！)内积运算中，l0和w1的位置不能颠倒\n",
        "\n",
        "    d_A1=d_tanh(l0_in)  #求tanh的偏导\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(img_lab,img_data,b0,b1,w1)  #求：y-output\n",
        "\n",
        "    mid_temp_1=np.dot(d_A2,diff)   #求：(y-output)*d_A2\n",
        "\n",
        "    mid_temp_2=np.dot(w1,mid_temp_1)   #求：w1*(y-output)*d_A2\n",
        "\n",
        "    result = np.dot(d_A1,mid_temp_2)#   #求：w1*(y-output)*d_A2*d_A1\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#定义loss函数\n",
        "def get_loss(img_lab,img_data,b0,b1,w1):\n",
        "    diff = diff_yreal_ypredict(img_lab,img_data,b0,b1,w1)\n",
        "    return ((diff**2)/10).sum()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "b0=init_parematers(784, 10)[0]['b0']\n",
        "\n",
        "w1=init_parematers(784, 10)[1]['w1']\n",
        "\n",
        "b1=init_parematers(784, 10)[1]['b1']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "随机loss: 0.9965465352997026\n",
            "训练loss:1.1464716261005812e-07\n"
          ]
        }
      ],
      "source": [
        "index=164\n",
        "learning_rate=0.5\n",
        "train_epoch=1000\n",
        "y=np.eye(10)\n",
        "\n",
        "img_data=train_img[index]\n",
        "img_lab=train_lab[index]\n",
        "\n",
        "\n",
        "l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "l0_out=tanh(l0_in)\n",
        "l1_in=np.dot(l0_out,w1)+b1\n",
        "l1_out=softmax(l1_in)\n",
        "\n",
        "y_predict=l1_out\n",
        "\n",
        "diff=y[img_lab]-y_predict\n",
        "loss=((diff**2).sum())\n",
        "print(\"随机loss:\",loss)\n",
        "\n",
        "######训练\n",
        "for i in range(train_epoch):\n",
        "    if loss<1e-02 :\n",
        "        break\n",
        "\n",
        "    d_b1=L_to_b1(img_lab,img_data,b0,b1,w1)\n",
        "    d_w1=L_to_w1(img_lab,img_data,b0,b1,w1)\n",
        "    d_b0=L_to_b0(img_lab,img_data,b0,b1,w1)\n",
        "\n",
        "    b1=b1+d_b1*learning_rate\n",
        "    w1=w1+d_w1*learning_rate\n",
        "    b0=b0+d_b0*learning_rate\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "    l1_out=softmax(l1_in)\n",
        "\n",
        "    y_predict=l1_out\n",
        "\n",
        "    diff=y[img_lab]-y_predict\n",
        "    loss=((diff**2).sum())\n",
        "    print(\"训练loss:{}\".format(loss))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "标签的数字是4\n",
            "[0.01216928 0.27095532 0.0057455  0.00265898 0.25788911 0.10671454\n",
            " 0.01740801 0.29095635 0.00044407 0.03505884]\n",
            "0.07219094879459821\n"
          ]
        }
      ],
      "source": [
        "index=26\n",
        "# learning_rate=0.01\n",
        "# train_epoch=2000\n",
        "# y=np.eye(10)\n",
        "\n",
        "img_data=train_img[index]\n",
        "img_lab=train_lab[index]\n",
        "print(\"标签的数字是{}\".format(img_lab))\n",
        "\n",
        "l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "l0_out=tanh(l0_in)\n",
        "l1_in=np.dot(l0_out,w1)+b1\n",
        "l1_out=softmax(l1_in)\n",
        "\n",
        "y_predict=l1_out\n",
        "print(y_predict)\n",
        "\n",
        "diff=y[img_lab]-y_predict\n",
        "\n",
        "loss=((diff**2).sum())/10\n",
        "print(loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "#################训练正式开始#################\n",
        "b0=init_parematers(784, 10)[0]['b0']\n",
        "\n",
        "w1=init_parematers(784, 10)[1]['w1']\n",
        "\n",
        "b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "batch_size=100   #100张图片为一组\n",
        "\n",
        "total_batch=train_set_num // batch_size   #总共有500个组\n",
        "\n",
        "# index=0\n",
        "\n",
        "learning_rate=0.5\n",
        "train_epoch=2000\n",
        "\n",
        "y=np.eye(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-第0次的第37891张图片 随机loss:1.063758938107521\n",
            "--第0次的第37891张图片的第0代 训练loss:0.044850805069963036\n",
            "--第0次的第37891张图片的第1代 训练loss:2.4724881596339126e-05\n",
            "-第1次的第40010张图片 随机loss:1.7875424399002626\n",
            "--第1次的第40010张图片的第0代 训练loss:1.1157455672603827\n",
            "--第1次的第40010张图片的第1代 训练loss:0.009417342852497705\n",
            "-第2次的第49806张图片 随机loss:0.9230431591474828\n",
            "--第2次的第49806张图片的第0代 训练loss:2.3447243343077498e-05\n",
            "-第3次的第29822张图片 随机loss:1.913694881763746\n",
            "--第3次的第29822张图片的第0代 训练loss:1.197990678087256\n",
            "--第3次的第29822张图片的第1代 训练loss:0.09348467226762276\n",
            "--第3次的第29822张图片的第2代 训练loss:2.600911539487917e-06\n",
            "-第4次的第18094张图片 随机loss:1.7469231861787118\n",
            "--第4次的第18094张图片的第0代 训练loss:0.8595525782758289\n",
            "--第4次的第18094张图片的第1代 训练loss:2.300650890440217e-09\n",
            "-第5次的第42945张图片 随机loss:1.9897076185713585\n",
            "--第5次的第42945张图片的第0代 训练loss:1.9832009201271532\n",
            "--第5次的第42945张图片的第1代 训练loss:1.9628414748298715\n",
            "--第5次的第42945张图片的第2代 训练loss:1.8046400027053777\n",
            "--第5次的第42945张图片的第3代 训练loss:1.5259492034490594\n",
            "--第5次的第42945张图片的第4代 训练loss:0.01069606953674779\n",
            "--第5次的第42945张图片的第5代 训练loss:0.0005200953459430198\n",
            "-第6次的第39292张图片 随机loss:1.5329547727013095\n",
            "--第6次的第39292张图片的第0代 训练loss:1.994949722222943e-10\n",
            "-第7次的第26490张图片 随机loss:4.246545927052068e-06\n",
            "-第8次的第1976张图片 随机loss:1.2798562197217718\n",
            "--第8次的第1976张图片的第0代 训练loss:1.2086483720815484\n",
            "--第8次的第1976张图片的第1代 训练loss:0.00039602961831296046\n",
            "-第9次的第41328张图片 随机loss:1.1959435703544845\n",
            "--第9次的第41328张图片的第0代 训练loss:1.0617264163102351\n",
            "--第9次的第41328张图片的第1代 训练loss:0.04208169840803866\n",
            "--第9次的第41328张图片的第2代 训练loss:0.001305699210451712\n"
          ]
        }
      ],
      "source": [
        "b0=init_parematers(784, 10)[0]['b0']\n",
        "\n",
        "w1=init_parematers(784, 10)[1]['w1']\n",
        "\n",
        "b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "batch_size=100   #100张图片为一组\n",
        "\n",
        "total_batch=train_set_num // batch_size   #总共有500个组\n",
        "\n",
        "# index=0\n",
        "\n",
        "learning_rate=0.5\n",
        "train_epoch=2000\n",
        "\n",
        "y=np.eye(10)\n",
        "\n",
        "for i in range(10):\n",
        "    current_img=np.random.randint(50000)\n",
        "    img_data=train_img[current_img]\n",
        "    img_lab=train_lab[current_img]\n",
        "\n",
        "    l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "    l1_out=softmax(l1_in)\n",
        "\n",
        "    y_predict=l1_out\n",
        "\n",
        "    diff=y[img_lab]-y_predict\n",
        "    loss=((diff**2).sum())\n",
        "    print(\"-第{}次的第{}张图片 随机loss:{}\".format(i,current_img,loss))\n",
        "\n",
        "    for epoch_index in range(train_epoch):\n",
        "        if loss<1e-02 :\n",
        "            break\n",
        "\n",
        "        d_b1=L_to_b1(img_lab,img_data,b0,b1,w1)\n",
        "        d_w1=L_to_w1(img_lab,img_data,b0,b1,w1)\n",
        "        d_b0=L_to_b0(img_lab,img_data,b0,b1,w1)\n",
        "\n",
        "        b1=b1+d_b1*learning_rate\n",
        "        w1=w1+d_w1*learning_rate\n",
        "        b0=b0+d_b0*learning_rate\n",
        "\n",
        "        l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "        l0_out=tanh(l0_in)\n",
        "        l1_in=np.dot(l0_out,w1)+b1\n",
        "        l1_out=softmax(l1_in)\n",
        "\n",
        "        y_predict=l1_out\n",
        "\n",
        "        diff=y[img_lab]-y_predict\n",
        "        loss=((diff**2).sum())\n",
        "        print(\"--第{}次的第{}张图片的第{}代 训练loss:{}\".format(i,current_img,epoch_index,loss))    \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for batch_index in range(total_batch):\n",
        "    for img_index in range(batch_size):\n",
        "        current_img=batch_index*batch_size+img_index\n",
        "\n",
        "        img_data=train_img[current_img]\n",
        "        img_lab=train_lab[current_img]\n",
        "\n",
        "        l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "        l0_out=tanh(l0_in)\n",
        "        l1_in=np.dot(l0_out,w1)+b1\n",
        "        l1_out=softmax(l1_in)\n",
        "\n",
        "        y_predict=l1_out\n",
        "\n",
        "        diff=y[img_lab]-y_predict\n",
        "        loss=((diff**2).sum())\n",
        "        print(\"-第{}个batch的第{}样本 随机loss:{}\".format(batch_index,img_index,loss))\n",
        "\n",
        "        for epoch_index in range(train_epoch):\n",
        "            if loss<1e-02 :\n",
        "                break\n",
        "\n",
        "            d_b1=L_to_b1(img_lab,img_data,b0,b1,w1)\n",
        "            d_w1=L_to_w1(img_lab,img_data,b0,b1,w1)\n",
        "            d_b0=L_to_b0(img_lab,img_data,b0,b1,w1)\n",
        "\n",
        "            b1=b1+d_b1*learning_rate\n",
        "            w1=w1+d_w1*learning_rate\n",
        "            b0=b0+d_b0*learning_rate\n",
        "\n",
        "            l0_in=img_data+b0  #l0=tanh(data+b0)\n",
        "            l0_out=tanh(l0_in)\n",
        "            l1_in=np.dot(l0_out,w1)+b1\n",
        "            l1_out=softmax(l1_in)\n",
        "\n",
        "            y_predict=l1_out\n",
        "\n",
        "            diff=y[img_lab]-y_predict\n",
        "            loss=((diff**2).sum())\n",
        "            print(\"--第{}个batch的第{}样本的第{}代 训练loss:{}\".format(batch_index,img_index,epoch_index,loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
