{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZUwG7ospUqzN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "###############第一节课：搭建网络框架、初始化网络参数##########################\n",
        "dimensions=[28*28, 10]    #第一个参数是图片的维度，第二个参数是output的维度"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPBxsuG-iqCb"
      },
      "outputs": [],
      "source": [
        "#定义激活函数\n",
        "def tanh(x):\n",
        "    x=np.array(x)\n",
        "    return np.tanh(x)\n",
        "\n",
        "    \n",
        "def softmax(x):\n",
        "    x=np.array(x)\n",
        "    exp = np.exp(x)   # x-x.max()的作用是防止指数爆炸，在经过相减运算后，不影响最后的结果\n",
        "    return exp/exp.sum()      #因为在代码中使用了x.max()，而普通数组是没有这样的max函数的，而np.array()有\n",
        "                              #所以在传参进softmax(x)时，要传进来np.array(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#定义初始化参数的函数\n",
        "def init_parematers(input_dim, output_dim):  #参数为输入图片的维度和输出图片的维度\n",
        "    b0 = np.zeros(input_dim)   #b0为全零，大小为784*1\n",
        "    b1 = np.zeros(output_dim)  #b1为全零，大小为10*1\n",
        "    w1 = np.random.rand(input_dim, output_dim)  #w1为随机，大小为784*10\n",
        "    \n",
        "    init_parameters_b_w = [   #以字典的形式返回所有参数\n",
        "        {'b0':b0},\n",
        "        {'b1':b1, 'w1':w1}\n",
        "    ]\n",
        "    return init_parameters_b_w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##########################第二节课：读取并显示MNIST中的数据##################################\n",
        "#设置训练集，验证集和测试集\n",
        "train_set_num = 50000\n",
        "valid_set_num = 10000\n",
        "test_set_num = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#读取MNIST文件\n",
        "import os\n",
        "\n",
        "root_path = os.path.abspath('.')  #获取当前文件夹的绝对路径\n",
        "\n",
        "train_img_path = os.path.join(root_path,\"MNIST\\\\train-images.idx3-ubyte\") #join()函数能将两个参数地址拼接到一起\n",
        "train_lab_path = os.path.join(root_path,\"MNIST\\\\train-labels.idx1-ubyte\")\n",
        "\n",
        "test_img_path = os.path.join(root_path,\"MNIST\\\\t10k-images.idx3-ubyte\")\n",
        "test_lab_path = os.path.join(root_path,\"MNIST\\\\t10k-labels.idx1-ubyte\")\n",
        "\n",
        "# 读取训练集中的图片数据\n",
        "with open(train_img_path, 'rb') as t:  \n",
        "    t.seek(16)    #因为train-images.idx3-ubyte中，前16个字节的数据是描述这个文件的，所以真正的数据是从16后面开始的\n",
        "    train_img = np.fromfile(t,dtype=np.uint8).reshape(-1,28*28)  #np.fromfile()作用：从文本或二进制文件中的数据构造一个数组\n",
        "    #reshape(-1,28*28)的解释：-1代表自动检测，因为不知道源文件中有多少个手写体数字，但是知道每个图片都是28*28的，所以第一个参数为-1就代表自动检测文件中有多少个28*28的图片\n",
        "    train_img = train_img[:train_set_num]   #从60000训练集中分离出前50000个为真正的训练集\n",
        "    valid_img = train_img[valid_set_num:]   #从60000训练集中分离出后10000个为验证集\n",
        "\n",
        "# 读取训练集中的标签数据\n",
        "with open(train_lab_path, 'rb') as t:  \n",
        "    t.seek(8)    #在train-labels.idx1-ubyte中，前8个字节的数据是描述这个文件的\n",
        "    train_lab = np.fromfile(t,dtype=np.uint8)\n",
        "    train_lab = train_lab[:train_set_num]   \n",
        "    valid_lab = train_lab[valid_set_num:]\n",
        "\n",
        "# 读取测试集中的图片数据\n",
        "with open(test_img_path, 'rb') as t:  \n",
        "    t.seek(16) \n",
        "    test_img = np.fromfile(t,dtype=np.uint8).reshape(-1,28*28)\n",
        "\n",
        "\n",
        "# 读取测试集中的标签数据\n",
        "with open(test_lab_path, 'rb') as t:  \n",
        "    t.seek(8)    \n",
        "    test_lab = np.fromfile(t,dtype=np.uint8)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#把数据画出来\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#画出训练集数据\n",
        "def show_train_img(index):\n",
        "    img = train_img[index].reshape(28,28)  #前面读取图片时的28*28是告诉程序每一张图片有多大，最后仍然是按行来储存读出来的数据（即:1*784的一维数据），而此处的28*28则是将读出来的那个一维数据转换成二维交给画图程序画图\n",
        "    plt.imshow(img, cmap=\"gray\")     #用灰度的格式将图片画出来\n",
        "    print(\"train_data:{}\".format(train_lab[index]))     #打印图片对应的标签\n",
        "\n",
        "#画出验证集数据\n",
        "def show_valid_img(index):\n",
        "    img = valid_img[index].reshape(28,28)\n",
        "    plt.imshow(img,cmap=\"gray\")\n",
        "    print(\"valid_data:{}\".format(valid_lab[index]))\n",
        "\n",
        "#画出测试集数据\n",
        "def show_test_img(index):\n",
        "    img = test_img[index].reshape(28,28)\n",
        "    plt.imshow(img,cmap=\"gray\")\n",
        "    print(\"test_data:{}\".format(test_lab[index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#显示训练集图片和标签\n",
        "show_train_img(np.random.randint(60000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#显示验证集的图片和标签\n",
        "show_valid_img(np.random.randint(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#显示测试集图片和标签\n",
        "show_test_img(np.random.randint(10000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "################第四节课：反向传播和梯度下降更新网络中的参数#################################\n",
        "# 计算梯度下降所用到的导数\n",
        "# 注意！！！(传参时，参数中所有的x必须是np的数组对象)\n",
        "h=0.0001\n",
        "\n",
        "#用导数极限的定义求tanh的导数\n",
        "def d_tanh_approximation(x):   \n",
        "    x=np.array(x)\n",
        "    return ((tanh(x+h)-tanh(x))/h)\n",
        "\n",
        "#直接对tanh求导，得到准确的值\n",
        "def d_tanh_precise(x):   \n",
        "    x=np.array(x)\n",
        "    return 1-tanh(x)**2\n",
        "\n",
        "#用导数极限的定义求softmax的导数\n",
        "def d_softmax(x):\n",
        "    x=np.array(x)\n",
        "    return ((softmax(x+h)-softmax(x))/h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#计算y_real和y_predict的差值\n",
        "def diff_yreal_ypredict(lab_num,flatten_img):\n",
        "    b0=init_parematers(784, 10)[0]['b0']\n",
        "    w1=init_parematers(784, 10)[1]['w1']\n",
        "    b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=flatten_img+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "\n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "    l1_out=softmax(l1_in)\n",
        "\n",
        "    y_predict=l1_out #用y_predict来代表预测值\n",
        "\n",
        "    y_real=[0 for i in range(10)]  #y_real为长度为10的数组\n",
        "    y_real=np.eye(10)              #生成10*10的对角矩阵\n",
        "    y_real=y_real.reshape(-1,1*10)  #用y_real来代表真实世界的值，y_real[0]就代表[1 0 0 0 0 0 0 0 0]，即label=1的数字的理想输出, y_real[1]同理\n",
        "    \n",
        "    return y_real[lab_num]-y_predict  #返回差值"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#计算梯度下降\n",
        "\n",
        "#求L对b1的偏导数=-2 * (y-output) * d_A2\n",
        "# 注意！！！(lab_num是从0开始的，所以lab_num=1代表标签2)\n",
        "def L_to_b1(lab_num,flatten_img):\n",
        "    b0=init_parematers(784, 10)[0]['b0']\n",
        "    w1=init_parematers(784, 10)[1]['w1']\n",
        "    b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=flatten_img+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(lab_num-1,flatten_img)  #求y-output的差值\n",
        "\n",
        "    result=-2*(d_A2*diff)    #计算L对b1的偏导数的结果\n",
        "   \n",
        "    return result\n",
        "\n",
        "#求L对w1的偏导数=-2 * (y-output) * d_A2 * l0\n",
        "# 注意！！！(lab_num是从0开始的，所以lab_num=1代表标签2)\n",
        "def L_to_w1(lab_num,flatten_img):\n",
        "    b0=init_parematers(784, 10)[0]['b0']\n",
        "    w1=init_parematers(784, 10)[1]['w1']\n",
        "    b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=flatten_img+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1\n",
        "\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(lab_num-1,flatten_img)  #求y-output的差值\n",
        "\n",
        "    mid_temp=d_A2*diff    #计算L对b1的偏导数的结果\n",
        "\n",
        "    l0_out=l0_out.reshape(784,1)\n",
        "    mid_temp=mid_temp.reshape(1,10)\n",
        "\n",
        "    result=np.dot(l0_out,mid_temp)\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "#求L对b1的偏导数=-2 * (y-output) * d_A2 * w1 * d_A1  (d_A2代表队A2求导，A2是第二层的激活函数“softmax”，A1是第一层的激活函数“tanh”)\n",
        "# 注意！！！(lab_num是从0开始的，所以lab_num=1代表标签2)\n",
        "def L_to_b0(lab_num,flatten_img):\n",
        "    b0=init_parematers(784, 10)[0]['b0']\n",
        "    w1=init_parematers(784, 10)[1]['w1']\n",
        "    b1=init_parematers(784, 10)[1]['b1']\n",
        "\n",
        "    l0_in=flatten_img+b0  #l0=tanh(data+b0)\n",
        "    l0_out=tanh(l0_in)\n",
        "    \n",
        "    l1_in=np.dot(l0_out,w1)+b1  #l1=softmax(w1*l0+b1)   (注意！)内积运算中，l0和w1的位置不能颠倒\n",
        "\n",
        "    d_A1=d_tanh_precise(l0_in)  #求tanh的偏导\n",
        "    d_A2=d_softmax(l1_in)  #求softmax的偏导\n",
        "\n",
        "    diff=diff_yreal_ypredict(lab_num-1,flatten_img)  #求：y-output\n",
        "\n",
        "    mid_temp_1=diff*d_A2   #求：(y-output)*d_A2\n",
        "\n",
        "    mid_temp_2=np.dot(w1,mid_temp_1)   #求：w1*(y-output)*d_A2\n",
        "\n",
        "    result = mid_temp_2*d_A1   #求：w1*(y-output)*d_A2*d_A1\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
